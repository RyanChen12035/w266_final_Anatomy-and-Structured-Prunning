{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PupqfkhD3BmH"
      },
      "outputs": [],
      "source": [
        "!pip install pydot --quiet\n",
        "!pip install tensorflow-datasets --quiet\n",
        "!pip install transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_BmiOKl3N4Q",
        "outputId": "69a6fced-4c56-4603-fe7e-6a7552347d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raA8ggyi3O1S",
        "outputId": "0e86f1e1-35f2-484a-d8b2-58bfffea1665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-e8bff272-c84b-f400-02e4-64c672740871)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda, Dropout, Conv1D, GlobalMaxPooling1D, Concatenate, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_datasets as tfds\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel, GPT2Config\n",
        "import sklearn as sk\n",
        "import os\n",
        "from nltk.data import find\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "iW4BBEmX3Pwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = tfds.load(\n",
        "    name=\"imdb_reviews\",\n",
        "    split=('train[:80%]', 'test[80%:]'),\n",
        "    as_supervised=True)\n",
        "\n",
        "train_examples, train_labels = next(iter(train_data.batch(20000)))\n",
        "val_examples, val_labels = next(iter(train_data.batch(5000)))\n",
        "test_examples, test_labels = next(iter(test_data.batch(1000)))"
      ],
      "metadata": {
        "id": "Xtu15Akr3RYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "config = GPT2Config.from_pretrained(\"gpt2\", output_hidden_states=True)\n",
        "gpt2_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", config=config)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "MAX_SEQUENCE_LENGTH = 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZgOWe6w3S6u",
        "outputId": "21f45823-b22b-4068-c1ef-f01535934e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Embedding size of GPT2 tokenizer: 768\n",
        "#Dictionary size of GPT2 tokenizer: 50257\n",
        "\n",
        "\n",
        "train_examples_str = [x.decode('utf-8') for x in train_examples.numpy()]\n",
        "val_examples_str = [x.decode('utf-8') for x in val_examples.numpy()]\n",
        "test_examples_str = [x.decode('utf-8') for x in test_examples.numpy()]\n",
        "\n",
        "#training data\n",
        "gpt_train_tokenized = tokenizer(train_examples_str,\n",
        "              max_length=MAX_SEQUENCE_LENGTH,\n",
        "              truncation=True,\n",
        "              padding='max_length',\n",
        "              return_tensors='tf')\n",
        "\n",
        "gpt_train_inputs = {\n",
        "    'input_ids': gpt_train_tokenized['input_ids'],\n",
        "    'attention_mask': gpt_train_tokenized['attention_mask']\n",
        "}\n",
        "\n",
        "gpt_train_labels = np.array(train_labels)\n",
        "\n",
        "\n",
        "#validation data\n",
        "gpt_val_tokenized = tokenizer(val_examples_str,\n",
        "              max_length=MAX_SEQUENCE_LENGTH,\n",
        "              truncation=True,\n",
        "              padding='max_length',\n",
        "              return_tensors='tf')\n",
        "\n",
        "gpt_val_inputs = {\n",
        "    'input_ids': gpt_val_tokenized['input_ids'],\n",
        "    'attention_mask': gpt_val_tokenized['attention_mask']\n",
        "}\n",
        "\n",
        "gpt_val_labels = np.array(val_labels)\n",
        "\n",
        "#testing data\n",
        "gpt_test_tokenized = tokenizer(test_examples_str,\n",
        "              max_length=MAX_SEQUENCE_LENGTH,\n",
        "              truncation=True,\n",
        "              padding='max_length',\n",
        "              return_tensors='tf')\n",
        "\n",
        "gpt_test_inputs = {\n",
        "    'input_ids': gpt_test_tokenized['input_ids'],\n",
        "    'attention_mask': gpt_test_tokenized['attention_mask']\n",
        "}\n",
        "\n",
        "gpt_test_labels = np.array(test_labels)\n"
      ],
      "metadata": {
        "id": "t9izibAJ3TCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#24 layers of transformer\n",
        "#A drop out layer + dense layer with 100 hidden layer size on top + final layer with sigmoid as activation function\n",
        "\n",
        "\n",
        "def create_gpt_last_model(gpt_model,\n",
        "                          max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "                          hidden_size = 100,\n",
        "                          dropout=0.3,\n",
        "                          learning_rate=0.00005):\n",
        "    \"\"\"\n",
        "    Build a simple classification model with gpt. Use the last token output for classification purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    gpt_model.trainable = True #True\n",
        "\n",
        "    #input layers of gpt, shape (batch, max_sequence_length), model will be fit with gpt_train_inputs\n",
        "    input_ids = Input(shape=(max_sequence_length,), dtype=tf.int32, name='input_ids')\n",
        "    attention_mask = Input(shape=(max_sequence_length,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "    # GPT-2 model\n",
        "    #model.generate() for iteratively generating (autoregressive)\n",
        "    #we only do it one time.\n",
        "    gpt2_outputs = gpt_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Use the last hidden state of the last transformer layer for classification, ingore linear layer and softmax layer\n",
        "    # Select the last token of hidden state\n",
        "    last_hidden_state_last_token = gpt2_outputs.logits[:, -1, :]\n",
        "\n",
        "    #Add a dropout layer\n",
        "    x = Dropout(dropout)(last_hidden_state_last_token)\n",
        "\n",
        "    #Add a fully connected layer for classification\n",
        "    x = Dense(hidden_size, activation='relu')(x)\n",
        "\n",
        "    #Final output layer for classification, assuming it's binary task\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "    # Create the model\n",
        "    classification_model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
        "\n",
        "\n",
        "    #Model complie\n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                                 loss='binary_crossentropy',\n",
        "                                 metrics=['accuracy'])\n",
        "\n",
        "    return classification_model\n"
      ],
      "metadata": {
        "id": "aKOSzfcK3TE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "pK3qHQ5_2PuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_logit_model_classification = create_gpt_last_model(gpt2_model)\n",
        "\n",
        "history = gpt_logit_model_classification.fit(gpt_train_inputs,\n",
        "                    gpt_train_labels,\n",
        "                    epochs=2, #2\n",
        "                    batch_size=8,\n",
        "                    validation_data=(gpt_val_inputs, gpt_val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIg3YYai3THS",
        "outputId": "3ec90c7a-7d1e-418b-e414-ba54796e3baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "2500/2500 [==============================] - 798s 309ms/step - loss: 0.7251 - accuracy: 0.7657 - val_loss: 0.3738 - val_accuracy: 0.8738\n",
            "Epoch 2/2\n",
            "2500/2500 [==============================] - 762s 305ms/step - loss: 0.4684 - accuracy: 0.7556 - val_loss: 0.4649 - val_accuracy: 0.8986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model before zeroing out\n",
        "gpt_logit_model_classification.evaluate(gpt_test_inputs, gpt_test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kLDJcIZ3TJp",
        "outputId": "0473f071-2cc2-452f-b384-33115a17fea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 14s 367ms/step - loss: 0.5087 - accuracy: 0.8520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5087048411369324, 0.8519999980926514]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "prediction = gpt_logit_model_classification.predict(gpt_test_inputs)\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))"
      ],
      "metadata": {
        "id": "T3Wk4ax03TMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af1309b6-474e-4f88-9e89-c17c051d561d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 15s 386ms/step\n",
            "Elapsed time: 23.37 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Cosine similiarity >　0.35\n",
        "\n",
        "=================Input 0====================\n",
        "Layer 10, Neurons: ['Layer 10 Neuron 804']\n",
        "Layer 11, Neurons: ['Layer 11 Neuron 309', 'Layer 11 Neuron 458', 'Layer 11 Neuron 598', 'Layer 11 Neuron 1120', 'Layer 11 Neuron 1126', 'Layer 11 Neuron 1289', 'Layer 11 Neuron 1322', 'Layer 11 Neuron 1637', 'Layer 11 Neuron 1860']\n",
        "\n",
        "=================Input 1====================\n",
        "Layer 10, Neurons: ['Layer 10 Neuron 804', 'Layer 10 Neuron 1410', 'Layer 10 Neuron 1521', 'Layer 10 Neuron 1783', 'Layer 10 Neuron 2931']\n",
        "Layer 11, Neurons: ['Layer 11 Neuron 309', 'Layer 11 Neuron 458', 'Layer 11 Neuron 480', 'Layer 11 Neuron 598', 'Layer 11 Neuron 796', 'Layer 11 Neuron 847', 'Layer 11 Neuron 869', 'Layer 11 Neuron 975', 'Layer 11 Neuron 1120', 'Layer 11 Neuron 1126',\n",
        "                    'Layer 11 Neuron 1231', 'Layer 11 Neuron 1289', 'Layer 11 Neuron 1322', 'Layer 11 Neuron 1428', 'Layer 11 Neuron 1575', 'Layer 11 Neuron 1637', 'Layer 11 Neuron 1860', 'Layer 11 Neuron 1998', 'Layer 11 Neuron 2375',\n",
        "                    'Layer 11 Neuron 2378', 'Layer 11 Neuron 2600', 'Layer 11 Neuron 2822']\n",
        "\n",
        "=================Input 2====================\n",
        "Layer 10, Neurons: ['Layer 10 Neuron 804']\n",
        "Layer 11, Neurons: ['Layer 11 Neuron 309', 'Layer 11 Neuron 458', 'Layer 11 Neuron 598', 'Layer 11 Neuron 1120', 'Layer 11 Neuron 1126', 'Layer 11 Neuron 1289', 'Layer 11 Neuron 1322', 'Layer 11 Neuron 1637', 'Layer 11 Neuron 1860']\n",
        "\n",
        "=================Input 3====================\n",
        "Layer 10, Neurons: ['Layer 10 Neuron 804', 'Layer 10 Neuron 1410', 'Layer 10 Neuron 1521', 'Layer 10 Neuron 1783', 'Layer 10 Neuron 2931']\n",
        "Layer 11, Neurons: ['Layer 11 Neuron 309', 'Layer 11 Neuron 458', 'Layer 11 Neuron 480', 'Layer 11 Neuron 598', 'Layer 11 Neuron 796', 'Layer 11 Neuron 847', 'Layer 11 Neuron 869', 'Layer 11 Neuron 975', 'Layer 11 Neuron 1120', 'Layer 11 Neuron 1126',\n",
        "                    'Layer 11 Neuron 1231', 'Layer 11 Neuron 1289', 'Layer 11 Neuron 1322', 'Layer 11 Neuron 1428', 'Layer 11 Neuron 1575', 'Layer 11 Neuron 1637', 'Layer 11 Neuron 1860', 'Layer 11 Neuron 1998', 'Layer 11 Neuron 2375',\n",
        "                    'Layer 11 Neuron 2378', 'Layer 11 Neuron 2600', 'Layer 11 Neuron 2822']\n",
        "\n",
        "=================Input 4====================\n",
        "Layer 10, Neurons: ['Layer 10 Neuron 804', 'Layer 10 Neuron 1410']\n",
        "Layer 11, Neurons: ['Layer 11 Neuron 309', 'Layer 11 Neuron 458', 'Layer 11 Neuron 480', 'Layer 11 Neuron 598', 'Layer 11 Neuron 796', 'Layer 11 Neuron 847', 'Layer 11 Neuron 1120', 'Layer 11 Neuron 1126', 'Layer 11 Neuron 1289', 'Layer 11 Neuron 1322',\n",
        "                    'Layer 11 Neuron 1637', 'Layer 11 Neuron 1860', 'Layer 11 Neuron 2375', 'Layer 11 Neuron 2378']\n",
        "\n",
        "=================Input 5====================\n",
        "Layer 10, Neurons: ['Layer 10 Neuron 804']\n",
        "Layer 11, Neurons: ['Layer 11 Neuron 309', 'Layer 11 Neuron 458', 'Layer 11 Neuron 1126', 'Layer 11 Neuron 1289', 'Layer 11 Neuron 1637', 'Layer 11 Neuron 1860']\n",
        "\n",
        "=================Input 6====================\n",
        "Layer 10, Neurons: ['Layer 10 Neuron 804', 'Layer 10 Neuron 1410']\n",
        "Layer 11, Neurons: ['Layer 11 Neuron 309', 'Layer 11 Neuron 458', 'Layer 11 Neuron 598', 'Layer 11 Neuron 1120', 'Layer 11 Neuron 1126', 'Layer 11 Neuron 1289', 'Layer 11 Neuron 1322', 'Layer 11 Neuron 1637', 'Layer 11 Neuron 1860', 'Layer 11 Neuron 2375',\n",
        "                    'Layer 11 Neuron 2378', 'Layer 11 Neuron 2822']\n",
        "\n",
        "=================Input 7====================\n",
        "Layer 10, Neurons: ['Layer 10 Neuron 804', 'Layer 10 Neuron 1410', 'Layer 10 Neuron 1783']\n",
        "Layer 11, Neurons: ['Layer 11 Neuron 309', 'Layer 11 Neuron 458', 'Layer 11 Neuron 480', 'Layer 11 Neuron 598', 'Layer 11 Neuron 796', 'Layer 11 Neuron 847', 'Layer 11 Neuron 975', 'Layer 11 Neuron 1120', 'Layer 11 Neuron 1126', 'Layer 11 Neuron 1231',\n",
        "                    'Layer 11 Neuron 1289', 'Layer 11 Neuron 1322', 'Layer 11 Neuron 1428', 'Layer 11 Neuron 1637', 'Layer 11 Neuron 1860', 'Layer 11 Neuron 2375', 'Layer 11 Neuron 2378', 'Layer 11 Neuron 2822']\n",
        "\n",
        "\n",
        "=================Input 8====================\n",
        "Layer 10, Neurons: ['Layer 10 Neuron 804']\n",
        "Layer 11, Neurons: ['Layer 11 Neuron 309', 'Layer 11 Neuron 458', 'Layer 11 Neuron 598', 'Layer 11 Neuron 1120', 'Layer 11 Neuron 1126', 'Layer 11 Neuron 1289', 'Layer 11 Neuron 1322', 'Layer 11 Neuron 1637', 'Layer 11 Neuron 1860']\n",
        "\n",
        "=================Input 9====================\n",
        "Layer 10, Neurons: ['Layer 10 Neuron 804', 'Layer 10 Neuron 1410']\n",
        "Layer 11, Neurons: ['Layer 11 Neuron 309', 'Layer 11 Neuron 458', 'Layer 11 Neuron 598', 'Layer 11 Neuron 1120', 'Layer 11 Neuron 1126', 'Layer 11 Neuron 1289', 'Layer 11 Neuron 1322', 'Layer 11 Neuron 1637', 'Layer 11 Neuron 1860', 'Layer 11 Neuron 2375', 'Layer 11 Neuron 2378']\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Create masks for each inputs and zero out the certain portion of neurons randomly except preserved neruons.\n",
        "#Mask after second layer of FFN\n",
        "preserved_neuron_list = [[],\n",
        "                       [],\n",
        "                       [],\n",
        "                       [],\n",
        "                       [],\n",
        "                       [],\n",
        "                       [],\n",
        "                       [],\n",
        "                       [],\n",
        "                       [],\n",
        "                       [804, 1410, 1521, 1783, 2931],\n",
        "                       [309, 458, 480, 598, 796, 847, 869, 975, 1120, 1126, 1231, 1289, 1322, 1428, 1575, 1637, 1860, 1998, 2375, 2378, 2600, 2822]]\n",
        "\n",
        "num_neurons = 3072\n",
        "masks = []\n",
        "\n",
        "original_list = list(range(3072))\n",
        "np.random.shuffle(original_list, )\n",
        "masked_neurons_list = [original_list[:307]]*12\n",
        "\n",
        "for i, masked_neurons in enumerate(masked_neurons_list):\n",
        "    mask = np.ones(num_neurons)\n",
        "    if masked_neurons not in preserved_neuron_list[i]:\n",
        "      mask[masked_neurons] = 0\n",
        "      masks.append(mask)"
      ],
      "metadata": {
        "id": "x7ua6dxE3TO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = 'tfgpt2lm_head_model/transformer/h_._0/mlp/c_proj/weight:0'\n",
        "layer.split('/')[2].split('_')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUU-waF-7ycC",
        "outputId": "66a4b68c-7bdf-4961-e57c-7b93fbc12e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['h', '.', '0']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#zero out -> quantization + sparse matrix pruning\n",
        "# Assuming bert_model is your pre-trained BERT model\n",
        "#tf_bert_model/bert/encoder/layer_._0/output/dense/kernel\n",
        "#  f\"tfgpt2lm_head_model/transformer/h_._{layer_num}/mlp/c_proj/weight:0\"\n",
        "\n",
        "\n",
        "for var in gpt2_model.variables:\n",
        "    if 'mlp/c_proj/weight' in var.name:\n",
        "        # Extract layer number from variable name\n",
        "        layer_num = int(var.name.split('/')[2].split('_')[2])\n",
        "\n",
        "        # Get the current weights\n",
        "        weights = var.numpy()\n",
        "\n",
        "        # Apply the mask #(3072,)\n",
        "        mask = masks[layer_num]\n",
        "        weights *= mask.reshape(-1, 1)  # Reshape mask and apply to weights\n",
        "\n",
        "        # Assign the modified weights back to the variable\n",
        "        var.assign(weights)\n"
      ],
      "metadata": {
        "id": "12lYAOgC7ZOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to check in if the weights are correctly zero out\n",
        "for var in gpt2_model.variables:\n",
        "    if 'mlp/c_proj/weight' in var.name:\n",
        "        print(var.name, var.numpy()[0:3, 0:3])  # Print a small section of the weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW2FS_lS8UMd",
        "outputId": "9d1583d9-d11e-411f-8d40-e5e8d8a45ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfgpt2lm_head_model/transformer/h_._0/mlp/c_proj/weight:0 [[-0.          0.          0.        ]\n",
            " [ 0.0384227  -0.06016427  0.08401392]\n",
            " [-0.          0.         -0.        ]]\n",
            "tfgpt2lm_head_model/transformer/h_._1/mlp/c_proj/weight:0 [[ 0.         -0.         -0.        ]\n",
            " [-0.20907356 -0.15552253 -0.08660339]\n",
            " [ 0.         -0.          0.        ]]\n",
            "tfgpt2lm_head_model/transformer/h_._2/mlp/c_proj/weight:0 [[-0.         -0.         -0.        ]\n",
            " [ 0.12518509  0.02254442 -0.12007061]\n",
            " [-0.         -0.         -0.        ]]\n",
            "tfgpt2lm_head_model/transformer/h_._3/mlp/c_proj/weight:0 [[ 0.          0.         -0.        ]\n",
            " [ 0.02451897 -0.00284892  0.04060924]\n",
            " [ 0.          0.          0.        ]]\n",
            "tfgpt2lm_head_model/transformer/h_._4/mlp/c_proj/weight:0 [[-0.          0.         -0.        ]\n",
            " [-0.08047505  0.01466465  0.13464928]\n",
            " [-0.          0.          0.        ]]\n",
            "tfgpt2lm_head_model/transformer/h_._5/mlp/c_proj/weight:0 [[ 0.          0.          0.        ]\n",
            " [-0.16617684  0.11109514 -0.12716916]\n",
            " [ 0.          0.          0.        ]]\n",
            "tfgpt2lm_head_model/transformer/h_._6/mlp/c_proj/weight:0 [[ 0.         -0.          0.        ]\n",
            " [ 0.04627054  0.12617528 -0.0417341 ]\n",
            " [-0.         -0.          0.        ]]\n",
            "tfgpt2lm_head_model/transformer/h_._7/mlp/c_proj/weight:0 [[ 0.         -0.          0.        ]\n",
            " [-0.02146071 -0.09958471 -0.02588684]\n",
            " [-0.          0.          0.        ]]\n",
            "tfgpt2lm_head_model/transformer/h_._8/mlp/c_proj/weight:0 [[-0.         -0.         -0.        ]\n",
            " [-0.2083479  -0.12895568 -0.07767013]\n",
            " [-0.          0.          0.        ]]\n",
            "tfgpt2lm_head_model/transformer/h_._9/mlp/c_proj/weight:0 [[ 0.         -0.         -0.        ]\n",
            " [-0.11698392 -0.09928118 -0.18097886]\n",
            " [-0.          0.         -0.        ]]\n",
            "tfgpt2lm_head_model/transformer/h_._10/mlp/c_proj/weight:0 [[ 0.          0.         -0.        ]\n",
            " [ 0.16706976 -0.20507327  0.01665138]\n",
            " [ 0.          0.         -0.        ]]\n",
            "tfgpt2lm_head_model/transformer/h_._11/mlp/c_proj/weight:0 [[ 0.          0.         -0.        ]\n",
            " [ 0.16435544  0.00750779  0.11573429]\n",
            " [-0.          0.         -0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bert_model has been zeroed out.\n",
        "gpt_logit_model_classification.evaluate(gpt_test_inputs, gpt_test_labels)\n",
        "\n",
        "#80~84\n",
        "#23 ~27.39\n",
        "#82, 23.06\n",
        "\n",
        "#            accuracy process time (1000 inputs)\n",
        "# 0%        --  0.844 27.39\n",
        "#10% (307)  --  0.827 11.93   0.856, 11.88 (0.852,23.37) 3684 neruons removed\n",
        "#30% (921)  --  0.657 11.81                              11052\n",
        "#50% (1531) --  0.582 12.59                              18372\n",
        "#70% (2150) --  0.509 11.78                              25800\n",
        "#80% (2457) --\n",
        "#90% (2764) --\n",
        "#95% (2922) --\n",
        "\n",
        "\n",
        "#Impending for further verifying"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw9l7XNy8ZCO",
        "outputId": "1e608d62-0447-4fb5-89c4-69c98012cc5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 12s 383ms/step - loss: 0.5137 - accuracy: 0.8560\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5137210488319397, 0.8560000061988831]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "prediction = gpt_logit_model_classification.predict(gpt_test_inputs)\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSc7RVH686GG",
        "outputId": "276c1902-ec7b-4a89-be10-f75d24dc4d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 12s 379ms/step\n",
            "Elapsed time: 11.88 seconds\n"
          ]
        }
      ]
    }
  ]
}