{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPbiKT6wp7SYExHeZsdO+Qz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1fc9ee9a37894ce1a92d79398558b595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f628bc571b3428d84ea275fbd3ce847",
              "IPY_MODEL_f2731467016d4bad8274e405a95c742a",
              "IPY_MODEL_da8501152eee413283d015cc491400ba"
            ],
            "layout": "IPY_MODEL_cd528b084f614ad487723e79efd0e421"
          }
        },
        "8f628bc571b3428d84ea275fbd3ce847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e6e039356c47bba5a4c8593db3e80f",
            "placeholder": "​",
            "style": "IPY_MODEL_05aa5c11096d4b76a213795575719779",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f2731467016d4bad8274e405a95c742a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6b85f90d7994f939c5cd5a2b76979cb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f44ac2450f745a1aae918fff1e368ec",
            "value": 2
          }
        },
        "da8501152eee413283d015cc491400ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aefa58f4bb14433b72b5bcff9b67419",
            "placeholder": "​",
            "style": "IPY_MODEL_fae7e73774f44d8781494da4f39fdc30",
            "value": " 2/2 [00:04&lt;00:00,  2.21s/it]"
          }
        },
        "cd528b084f614ad487723e79efd0e421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e6e039356c47bba5a4c8593db3e80f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05aa5c11096d4b76a213795575719779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6b85f90d7994f939c5cd5a2b76979cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f44ac2450f745a1aae918fff1e368ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3aefa58f4bb14433b72b5bcff9b67419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fae7e73774f44d8781494da4f39fdc30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "670da712c2d94a29a75978e6ebf08778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_baa0df3578754c3bad183558b71f87ab",
              "IPY_MODEL_bef1f18fe9e341dc848b1a4950fb86f8",
              "IPY_MODEL_63cb1e55876d4244a06e81d7120171e3"
            ],
            "layout": "IPY_MODEL_18964c6ff0244603a02ed59a53e6d93e"
          }
        },
        "baa0df3578754c3bad183558b71f87ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be973a1eba1d4c26bd99d2b76a24c0ed",
            "placeholder": "​",
            "style": "IPY_MODEL_afb05cc9794746debb234c1aafaa98a1",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "bef1f18fe9e341dc848b1a4950fb86f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c438cb897d1b4e3688a08e6bf3ce6da6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a52bc66db4c547c39fbc0fff54d03d05",
            "value": 2
          }
        },
        "63cb1e55876d4244a06e81d7120171e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_167503b428ba48b58b5d789a63f9aa5b",
            "placeholder": "​",
            "style": "IPY_MODEL_a5dfd4eefc4e4701b25f79a9847d719c",
            "value": " 2/2 [00:04&lt;00:00,  2.10s/it]"
          }
        },
        "18964c6ff0244603a02ed59a53e6d93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be973a1eba1d4c26bd99d2b76a24c0ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afb05cc9794746debb234c1aafaa98a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c438cb897d1b4e3688a08e6bf3ce6da6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52bc66db4c547c39fbc0fff54d03d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "167503b428ba48b58b5d789a63f9aa5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5dfd4eefc4e4701b25f79a9847d719c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cda8e0ed00d4cadbc7b8dddf09e32e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6548dfe1b110448e8554713f7b2ec093",
              "IPY_MODEL_5f2c72d213e04eae804ae8bfcd5848dc",
              "IPY_MODEL_fcc530563f444b5aaff054762849c3a4"
            ],
            "layout": "IPY_MODEL_91b71bf501684afbb0bb03dbb2a0bc7f"
          }
        },
        "6548dfe1b110448e8554713f7b2ec093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029fbc64723a4af6bcba450c2b808da3",
            "placeholder": "​",
            "style": "IPY_MODEL_fc55462fa1b345508a98d3272032d9cf",
            "value": "100%"
          }
        },
        "5f2c72d213e04eae804ae8bfcd5848dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d12be350081e47b6a368572b7da54a67",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3b08e30ba374f3e804af5bdeb805725",
            "value": 24
          }
        },
        "fcc530563f444b5aaff054762849c3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4d075c5e9a44587bd3ad33d62692f4d",
            "placeholder": "​",
            "style": "IPY_MODEL_3294baaac42449ef956720f9d9d8dcd0",
            "value": " 24/24 [00:51&lt;00:00,  2.24s/it]"
          }
        },
        "91b71bf501684afbb0bb03dbb2a0bc7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "029fbc64723a4af6bcba450c2b808da3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc55462fa1b345508a98d3272032d9cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d12be350081e47b6a368572b7da54a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b08e30ba374f3e804af5bdeb805725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4d075c5e9a44587bd3ad33d62692f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3294baaac42449ef956720f9d9d8dcd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanChen12035/w266_final_Anatomy-and-Structured-Prunning/blob/main/Llama2_ft_Qlora_boolq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ebS1BfHLRwZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e8a7bc4-f50b-4cb6-e206-68341c0bd572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft\n",
            "  Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, nvidia-cusolver-cu12, datasets, bitsandbytes, accelerate, peft\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed accelerate-0.30.1 bitsandbytes-0.43.1 datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 peft-0.11.1 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets accelerate peft bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model"
      ],
      "metadata": {
        "id": "st_pPEiFbnjn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'super_glue'\n",
        "config = 'boolq'\n",
        "dataset = load_dataset(dataset_name, config)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqI53BM8brK2",
        "outputId": "6bf552f4-660a-4110-821d-e3fdd3acc1f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question', 'passage', 'idx', 'label'],\n",
              "        num_rows: 9427\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['question', 'passage', 'idx', 'label'],\n",
              "        num_rows: 3270\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['question', 'passage', 'idx', 'label'],\n",
              "        num_rows: 3245\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def template_prompt_engineering(example):\n",
        "  # add system template of Llama2 and prompt engineering for the boolq task\n",
        "  example['label'] = \"the correct answer is true\" if example['label'] else \"the correct answer is false\"\n",
        "  example['question'] = f\"\"\"Please answer the following queation with true or false, question: {example['question']}?\\n\\nAnswer format: true/false\"\"\"\n",
        "  example['text'] = f\"\"\"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\n",
        "        ### Instruction:\n",
        "        {example['question']}[/INST]\n",
        "\n",
        "        ### Response:\n",
        "        {example['label']}\n",
        "        \"\"\"\n",
        "  return example\n",
        "\n",
        "dataset_withtemplate = dataset.map(template_prompt_engineering, remove_columns=['question', 'passage', 'idx', 'label'])\n",
        "dataset_withtemplate['train'].to_pandas()\n",
        "\n",
        "# it's a CLM (autoregressive task), the model would take the output of tokenizer as input and input shifting one position as label\n",
        "# we only need an input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "02ealDiCbuN4",
        "outputId": "15e00bb4-20d5-4659-87e0-e3a3105e64d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text\n",
              "0     <s>[INST]<<sys>>Below is an instruction that d...\n",
              "1     <s>[INST]<<sys>>Below is an instruction that d...\n",
              "2     <s>[INST]<<sys>>Below is an instruction that d...\n",
              "3     <s>[INST]<<sys>>Below is an instruction that d...\n",
              "4     <s>[INST]<<sys>>Below is an instruction that d...\n",
              "...                                                 ...\n",
              "9422  <s>[INST]<<sys>>Below is an instruction that d...\n",
              "9423  <s>[INST]<<sys>>Below is an instruction that d...\n",
              "9424  <s>[INST]<<sys>>Below is an instruction that d...\n",
              "9425  <s>[INST]<<sys>>Below is an instruction that d...\n",
              "9426  <s>[INST]<<sys>>Below is an instruction that d...\n",
              "\n",
              "[9427 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-396dd8b3-b4fd-454e-adc6-e1b2658c7e14\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9422</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9423</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9424</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9425</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9426</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9427 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-396dd8b3-b4fd-454e-adc6-e1b2658c7e14')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-396dd8b3-b4fd-454e-adc6-e1b2658c7e14 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-396dd8b3-b4fd-454e-adc6-e1b2658c7e14');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a4cb688-418f-473a-860d-5955af7ac18c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a4cb688-418f-473a-860d-5955af7ac18c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a4cb688-418f-473a-860d-5955af7ac18c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# we only need an input\",\n  \"rows\": 9427,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9427,\n        \"samples\": [\n          \"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\\n        ### Instruction:\\n        Please answer the following queation with true or false, question: did jurassic world fallen kingdom come out yet?\\n\\nAnswer format: true/false[/INST]\\n\\n        ### Response:\\n        the correct answer is true\\n        \",\n          \"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\\n        ### Instruction:\\n        Please answer the following queation with true or false, question: has there ever been a host team in the super bowl?\\n\\nAnswer format: true/false[/INST]\\n\\n        ### Response:\\n        the correct answer is false\\n        \",\n          \"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\\n        ### Instruction:\\n        Please answer the following queation with true or false, question: is it legal to have a radar detector in texas?\\n\\nAnswer format: true/false[/INST]\\n\\n        ### Response:\\n        the correct answer is true\\n        \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it's a CLM (autoregressive task), the model would take the output of tokenizer as input and input shifting one position as label\n",
        "# tokenize the dataset, the trainer would take the key world input_ids and attention mask generated by the tokenizer\n",
        "# Model\n",
        "base_model = \"NousResearch/Llama-2-7b-hf\"\n",
        "new_model = \"llama-2-7b-Qlora-boolq-test\"\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    text = examples[\"text\"]\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    )\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_data = dataset_withtemplate.map(tokenize_function, batched=True)\n",
        "\n",
        "# data collator for how to padding and truncating\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        "\n",
        "tokenized_data['train'].to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "2OFInHs5eekt",
        "outputId": "a95c6cb4-8210-4281-ba62-3c08fd799ce4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  \\\n",
              "0     <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "1     <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "2     <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "3     <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "4     <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "...                                                 ...   \n",
              "9422  <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "9423  <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "9424  <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "9425  <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "9426  <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "\n",
              "                                              input_ids  \\\n",
              "0     [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "1     [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "2     [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "3     [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "4     [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "...                                                 ...   \n",
              "9422  [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "9423  [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "9424  [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "9425  [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "9426  [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "\n",
              "                                         attention_mask  \n",
              "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "...                                                 ...  \n",
              "9422  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "9423  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "9424  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "9425  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "9426  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "\n",
              "[9427 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d783c26-d4d4-4aa9-a877-fbf3aef37d85\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9422</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9423</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9424</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9425</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9426</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9427 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d783c26-d4d4-4aa9-a877-fbf3aef37d85')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d783c26-d4d4-4aa9-a877-fbf3aef37d85 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d783c26-d4d4-4aa9-a877-fbf3aef37d85');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-062c0b50-3549-4532-b929-4ea1da8837df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-062c0b50-3549-4532-b929-4ea1da8837df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-062c0b50-3549-4532-b929-4ea1da8837df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tokenized_data['train']\",\n  \"rows\": 9427,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9427,\n        \"samples\": [\n          \"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\\n        ### Instruction:\\n        Please answer the following queation with true or false, question: did jurassic world fallen kingdom come out yet?\\n\\nAnswer format: true/false[/INST]\\n\\n        ### Response:\\n        the correct answer is true\\n        \",\n          \"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\\n        ### Instruction:\\n        Please answer the following queation with true or false, question: has there ever been a host team in the super bowl?\\n\\nAnswer format: true/false[/INST]\\n\\n        ### Response:\\n        the correct answer is false\\n        \",\n          \"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\\n        ### Instruction:\\n        Please answer the following queation with true or false, question: is it legal to have a radar detector in texas?\\n\\nAnswer format: true/false[/INST]\\n\\n        ### Response:\\n        the correct answer is true\\n        \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attention_mask\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data[\"validation\"].to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2768
        },
        "id": "cgBn5tzwhAFQ",
        "outputId": "2b936c9e-42a7-49b3-b842-0b701a954757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  \\\n",
              "0     <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "1     <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "2     <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "3     <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "4     <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "...                                                 ...   \n",
              "3265  <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "3266  <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "3267  <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "3268  <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "3269  <s>[INST]<<sys>>Below is an instruction that d...   \n",
              "\n",
              "                                              input_ids  \\\n",
              "0     [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "1     [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "2     [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "3     [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "4     [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "...                                                 ...   \n",
              "3265  [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "3266  [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "3267  [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "3268  [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "3269  [1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...   \n",
              "\n",
              "                                         attention_mask  \n",
              "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "...                                                 ...  \n",
              "3265  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3266  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3267  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3268  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3269  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "\n",
              "[3270 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-865a7b44-5669-4c27-8980-cc069e16b439\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3266</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3267</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3268</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3269</th>\n",
              "      <td>&lt;s&gt;[INST]&lt;&lt;sys&gt;&gt;Below is an instruction that d...</td>\n",
              "      <td>[1, 1, 29961, 25580, 29962, 9314, 9675, 6778, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3270 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-865a7b44-5669-4c27-8980-cc069e16b439')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-865a7b44-5669-4c27-8980-cc069e16b439 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-865a7b44-5669-4c27-8980-cc069e16b439');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fdc1cd2a-6515-4280-b60d-dc26e2822688\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fdc1cd2a-6515-4280-b60d-dc26e2822688')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fdc1cd2a-6515-4280-b60d-dc26e2822688 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tokenized_data[\\\"validation\\\"]\",\n  \"rows\": 3270,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3270,\n        \"samples\": [\n          \"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\\n        ### Instruction:\\n        Please answer the following queation with true' or false, question: is living at high altitude good for you?\\n\\nAnswer format: true/false?[/INST]\\n\\n        ### Response:\\n        the correct answer is false\\n        \",\n          \"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\\n        ### Instruction:\\n        Please answer the following queation with true' or false, question: is fate and the furious the last movie?\\n\\nAnswer format: true/false?[/INST]\\n\\n        ### Response:\\n        the correct answer is false\\n        \",\n          \"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\\n        ### Instruction:\\n        Please answer the following queation with true' or false, question: do the miami dolphins have a real dolphin in their stadium?\\n\\nAnswer format: true/false?[/INST]\\n\\n        ### Response:\\n        the correct answer is false\\n        \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attention_mask\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# base_model = \"NousResearch/Llama-2-7b-hf\"\n",
        "\n",
        "# Quantization configuration\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ") # project the model weights to 4bits, pass torch fp16\n",
        "\n",
        "\n",
        "# Load base moodel\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\": 0}\n",
        ") # download the CLM (autoregressive) model, calculate the loss function of next token.\n",
        "\n",
        "#checkpointing to reduce the payload\n",
        "model.gradient_checkpointing_enable()\n",
        "# Cast the layernorm in fp32, make output embedding layer require grads, add the upcasting of the lmhead to fp32\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "1fc9ee9a37894ce1a92d79398558b595",
            "8f628bc571b3428d84ea275fbd3ce847",
            "f2731467016d4bad8274e405a95c742a",
            "da8501152eee413283d015cc491400ba",
            "cd528b084f614ad487723e79efd0e421",
            "c2e6e039356c47bba5a4c8593db3e80f",
            "05aa5c11096d4b76a213795575719779",
            "e6b85f90d7994f939c5cd5a2b76979cb",
            "9f44ac2450f745a1aae918fff1e368ec",
            "3aefa58f4bb14433b72b5bcff9b67419",
            "fae7e73774f44d8781494da4f39fdc30"
          ]
        },
        "id": "wqEI616uhZB8",
        "outputId": "50d28e06-fcec-4fef-8171-aa940bdf0ba6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fc9ee9a37894ce1a92d79398558b595"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    r=16, # by analysis\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    layers_to_transform = [i for i in range(21, 32)], # layers from 6 to 11. by analysis\n",
        "    target_modules=['q_proj'] # query attention\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# all layers q_proj, trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.0622\n",
        "# 21~31 layers q_proj, trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.0214\n",
        "# 2~12 layers q_proj, trainable params: 655,360 || all params: 6,739,070,976 || trainable%: 0.0097 r = 8\n",
        "# 2~12 layers q_proj, trainable params: 655,360 || all params: 6,739,070,976 || trainable%: 0.0194 r = 16\n",
        "# all attention + MLP trainable params: 13,742,080 || all params: 6,752,157,696 || trainable%: 0.2035"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pbb1BchiKa5",
        "outputId": "9264aeb3-2439-45fd-9eb7-4729378d76c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,441,792 || all params: 6,739,857,408 || trainable%: 0.0214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "lr = 2e-4\n",
        "batch_size = 4\n",
        "num_epochs = 100\n",
        "\n",
        "# define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= \"llama2-ft-qlora-boolq\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    logging_strategy=\"epoch\", #update loss for each epochs\n",
        "    evaluation_strategy=\"epoch\", #update loss for each epochs\n",
        "    save_strategy=\"epoch\", #update loss for each epochs\n",
        "    load_best_model_at_end=True,\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_steps=2,\n",
        "    fp16=True,\n",
        "    optim=\"paged_adamw_8bit\", #balance the memory usage between CPU and GPU\n",
        ")\n",
        "\n",
        "\n",
        "# configure trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_data[\"train\"].select(range(24)),\n",
        "    eval_dataset=tokenized_data[\"validation\"].select(range(4)),\n",
        "    args=training_args,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# train model\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "trainer.train()\n",
        "\n",
        "# renable warnings\n",
        "model.config.use_cache = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZVfzoX6qgbT9",
        "outputId": "3c893b94-59e3-44f1-fa47-0b964f8510df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 09:52, Epoch 66/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.541400</td>\n",
              "      <td>3.743811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.520900</td>\n",
              "      <td>3.723219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.453200</td>\n",
              "      <td>3.672807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>5.339900</td>\n",
              "      <td>3.592165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>5.187700</td>\n",
              "      <td>3.488445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>5.010300</td>\n",
              "      <td>3.370367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>4.825600</td>\n",
              "      <td>3.248523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>4.628600</td>\n",
              "      <td>3.116778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>4.412700</td>\n",
              "      <td>2.972915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>4.184400</td>\n",
              "      <td>2.822065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.944400</td>\n",
              "      <td>2.661367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>3.672000</td>\n",
              "      <td>2.476094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>3.372700</td>\n",
              "      <td>2.289391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>3.174900</td>\n",
              "      <td>2.164379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>2.935200</td>\n",
              "      <td>2.000821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.717400</td>\n",
              "      <td>1.860445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>2.529200</td>\n",
              "      <td>1.736735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>2.360200</td>\n",
              "      <td>1.626251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>2.206500</td>\n",
              "      <td>1.527216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>2.063900</td>\n",
              "      <td>1.435375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.929300</td>\n",
              "      <td>1.347626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.799300</td>\n",
              "      <td>1.262559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.685300</td>\n",
              "      <td>1.191301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.597100</td>\n",
              "      <td>1.135999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.529700</td>\n",
              "      <td>1.094525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.476400</td>\n",
              "      <td>1.061550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.430800</td>\n",
              "      <td>1.032589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.388000</td>\n",
              "      <td>1.006055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.350400</td>\n",
              "      <td>0.981173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.315600</td>\n",
              "      <td>0.958985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.287700</td>\n",
              "      <td>0.942723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.270500</td>\n",
              "      <td>0.932838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.260400</td>\n",
              "      <td>0.927449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.834000</td>\n",
              "      <td>0.925545</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained model to variable new_model\n",
        "trainer.model.save_pretrained(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hmmtUATjwdQ",
        "outputId": "25906862-fa82-49b6-fb06-1c51d01c7f0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty VRAM\n",
        "del model\n",
        "# del pipe\n",
        "del trainer\n",
        "import gc\n",
        "gc.collect()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ynrza3kDxP",
        "outputId": "cd18a035-d7de-4eb1-d9ee-7e5e9b3c428f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reattach the lora on full digit model\n",
        "# Reload model in FP16 and merge it with LoRA weights\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map={\"\": 0},\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, new_model)\n",
        "model = model.merge_and_unload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "670da712c2d94a29a75978e6ebf08778",
            "baa0df3578754c3bad183558b71f87ab",
            "bef1f18fe9e341dc848b1a4950fb86f8",
            "63cb1e55876d4244a06e81d7120171e3",
            "18964c6ff0244603a02ed59a53e6d93e",
            "be973a1eba1d4c26bd99d2b76a24c0ed",
            "afb05cc9794746debb234c1aafaa98a1",
            "c438cb897d1b4e3688a08e6bf3ce6da6",
            "a52bc66db4c547c39fbc0fff54d03d05",
            "167503b428ba48b58b5d789a63f9aa5b",
            "a5dfd4eefc4e4701b25f79a9847d719c"
          ]
        },
        "id": "cMfZokT_kDz2",
        "outputId": "1f4adba6-1ebc-484c-bf1d-b5d8791d514e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "670da712c2d94a29a75978e6ebf08778"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "def template_prompt_engineering(example: str):\n",
        "  # add system template of Llama2 and prompt engineering for the boolq task\n",
        "  example = f\"\"\"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\n",
        "        ### Instruction:\n",
        "        Please answer the following queation with true' or false, question:{example}?\\n\\nAnswer format: true/false\n",
        "\n",
        "        [/INST]\n",
        "        ### Response:\n",
        "        \"\"\"\n",
        "  return example\n",
        "\n",
        "# Run text generation pipeline with our model\n",
        "prompt = \"does ethanol take more energy make that produces?\"\n",
        "templated_prompt = template_prompt_engineering(prompt)\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
        "result = pipe(templated_prompt)\n",
        "result_text = result[0]['generated_text']\n",
        "print(result_text[result_text.find('Response'):result_text.find('Response')+100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A89jcJE9kKJg",
        "outputId": "0e2a3a98-a8cb-45b1-a955-7edddc14e86a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "        \n",
            "        [/SYS]\n",
            "        ### Instruction:\n",
            "        Please answer the following queat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41B1yoEXlqLc",
        "outputId": "380c42fc-c21c-4f8e-94ea-fa7487f30e68"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\\n        ### Instruction:\\n        Please answer the following queation with true' or false, question:does ethanol take more energy make that produces??\\n\\nAnswer format: true/false\\n\\n        [/INST]\\n        ### Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queation with true' or false, question:does ethanol take more energy make that produces??\\n\\n\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# boolq evaluation"
      ],
      "metadata": {
        "id": "oKI9KgL1lBKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['validation'].to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Yr83_Wzk_mEu",
        "outputId": "f45107cf-7179-4eb4-a455-82ca903c24b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               question  \\\n",
              "0      does ethanol take more energy make that produces   \n",
              "1                is house tax and property tax are same   \n",
              "2     is pain experienced in a missing body part or ...   \n",
              "3     is harry potter and the escape from gringotts ...   \n",
              "4     is there a difference between hydroxyzine hcl ...   \n",
              "...                                                 ...   \n",
              "3265           is manic depression the same as bi polar   \n",
              "3266           was whiskey galore based on a true story   \n",
              "3267  are there plants on the international space st...   \n",
              "3268  does the hockey puck have to cross the line to...   \n",
              "3269          will there be a season 5 of shadowhunters   \n",
              "\n",
              "                                                passage   idx  label  \n",
              "0     Ethanol fuel -- All biomass goes through at le...     0      0  \n",
              "1     Property tax -- Property tax or 'house tax' is...     1      1  \n",
              "2     Phantom pain -- Phantom pain sensations are de...     2      1  \n",
              "3     Harry Potter and the Escape from Gringotts -- ...     3      1  \n",
              "4     Hydroxyzine -- Hydroxyzine preparations requir...     4      1  \n",
              "...                                                 ...   ...    ...  \n",
              "3265  Bipolar disorder -- Bipolar disorder, previous...  3265      1  \n",
              "3266  SS Politician -- SS Politician was an 8000-ton...  3266      1  \n",
              "3267  Plants in space -- Plant research continued on...  3267      1  \n",
              "3268  Goal (ice hockey) -- In ice hockey, a goal is ...  3268      1  \n",
              "3269  List of Shadowhunters episodes -- In April 201...  3269      0  \n",
              "\n",
              "[3270 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a550d4f-abbb-45db-8713-5d91303575e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>passage</th>\n",
              "      <th>idx</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>does ethanol take more energy make that produces</td>\n",
              "      <td>Ethanol fuel -- All biomass goes through at le...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is house tax and property tax are same</td>\n",
              "      <td>Property tax -- Property tax or 'house tax' is...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is pain experienced in a missing body part or ...</td>\n",
              "      <td>Phantom pain -- Phantom pain sensations are de...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>is harry potter and the escape from gringotts ...</td>\n",
              "      <td>Harry Potter and the Escape from Gringotts -- ...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is there a difference between hydroxyzine hcl ...</td>\n",
              "      <td>Hydroxyzine -- Hydroxyzine preparations requir...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265</th>\n",
              "      <td>is manic depression the same as bi polar</td>\n",
              "      <td>Bipolar disorder -- Bipolar disorder, previous...</td>\n",
              "      <td>3265</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3266</th>\n",
              "      <td>was whiskey galore based on a true story</td>\n",
              "      <td>SS Politician -- SS Politician was an 8000-ton...</td>\n",
              "      <td>3266</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3267</th>\n",
              "      <td>are there plants on the international space st...</td>\n",
              "      <td>Plants in space -- Plant research continued on...</td>\n",
              "      <td>3267</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3268</th>\n",
              "      <td>does the hockey puck have to cross the line to...</td>\n",
              "      <td>Goal (ice hockey) -- In ice hockey, a goal is ...</td>\n",
              "      <td>3268</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3269</th>\n",
              "      <td>will there be a season 5 of shadowhunters</td>\n",
              "      <td>List of Shadowhunters episodes -- In April 201...</td>\n",
              "      <td>3269</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3270 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a550d4f-abbb-45db-8713-5d91303575e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a550d4f-abbb-45db-8713-5d91303575e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a550d4f-abbb-45db-8713-5d91303575e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c6ad281e-bb6b-4cc9-b574-c84390a1155a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6ad281e-bb6b-4cc9-b574-c84390a1155a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c6ad281e-bb6b-4cc9-b574-c84390a1155a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset['validation']\",\n  \"rows\": 3270,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3270,\n        \"samples\": [\n          \"is living at high altitude good for you\",\n          \"is fate and the furious the last movie\",\n          \"do the miami dolphins have a real dolphin in their stadium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"passage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2939,\n        \"samples\": [\n          \"Cuvette -- Historically, reusable quartz cuvettes were required for measurements in the ultraviolet range, because glass and most plastics absorb ultraviolet light, creating interference. Today there are disposable plastic cuvettes made of specialized plastics that are transparent to ultraviolet light. Glass, plastic and quartz cuvettes are all suitable for measurements made at longer wavelengths, such as in the visible light range.\",\n          \"Universal Declaration of Human Rights -- The meeting record provides firsthand insight into the debate. South Africa's position can be seen as an attempt to protect its system of apartheid, which clearly violated several articles in the Declaration. The Saudi Arabian delegation's abstention was prompted primarily by two of the Declaration's articles: Article 18, which states that everyone has the right ``to change his religion or belief''; and Article 16, on equal marriage rights. The six communist countries abstentions centred around the view that the Declaration did not go far enough in condemning fascism and Nazism. Eleanor Roosevelt attributed the abstention of Soviet bloc countries to Article 13, which provided the right of citizens to leave their countries.\",\n          \"Differentiable function -- A function f is said to be continuously differentiable if the derivative f\\u2032(x) exists and is itself a continuous function. Though the derivative of a differentiable function never has a jump discontinuity, it is possible for the derivative to have an essential discontinuity. For example, the function\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idx\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 3270,\n        \"samples\": [\n          1644,\n          134,\n          411\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def template_prompt_engineering(example: str):\n",
        "  # add system template of Llama2 and prompt engineering for the boolq task\n",
        "  example = f\"\"\"<s>[INST]<<sys>>Below is an instruction that describes a task. Write a response that appropriately completes the request<</sys>>\n",
        "        ### Instruction:\n",
        "        Please answer the following queation with the words 'true' or 'false', question:{example}?\\n\\nAnswer format: true/false\n",
        "        [/INST]\n",
        "        ### Response:\n",
        "        \"\"\"\n",
        "  return example\n",
        "\n",
        "predictions = []\n",
        "for prompt in tqdm(dataset['train']['question'][:24]):\n",
        "    templated_prompt = template_prompt_engineering(prompt)\n",
        "    pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
        "    result = pipe(templated_prompt)\n",
        "    result_text = result[0]['generated_text']\n",
        "    # print(result_text[result_text.find('Response'):result_text.find('Response')+100])\n",
        "    predictions.append(result_text[result_text.find('Response'):result_text.find('Response')+100])\n",
        "\n",
        "\n",
        "def extract_boolean_label(text):\n",
        "    text = text.lower()\n",
        "    if 'true' in text:\n",
        "        return 1\n",
        "    elif 'false' in text:\n",
        "        return 0\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "binary_predictions = []\n",
        "for pred in predictions:\n",
        "    binary_predictions.append(extract_boolean_label(pred))\n",
        "\n",
        "y = dataset['train'][\"label\"][:24]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(np.array(y) == np.array(binary_predictions))\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5cda8e0ed00d4cadbc7b8dddf09e32e2",
            "6548dfe1b110448e8554713f7b2ec093",
            "5f2c72d213e04eae804ae8bfcd5848dc",
            "fcc530563f444b5aaff054762849c3a4",
            "91b71bf501684afbb0bb03dbb2a0bc7f",
            "029fbc64723a4af6bcba450c2b808da3",
            "fc55462fa1b345508a98d3272032d9cf",
            "d12be350081e47b6a368572b7da54a67",
            "c3b08e30ba374f3e804af5bdeb805725",
            "f4d075c5e9a44587bd3ad33d62692f4d",
            "3294baaac42449ef956720f9d9d8dcd0"
          ]
        },
        "id": "u17LXH-8_e4R",
        "outputId": "803fcb80-0be7-4565-c2c6-bfc0a99f8170"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/24 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cda8e0ed00d4cadbc7b8dddf09e32e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 58.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions\n",
        "\n",
        "#--high epochs: 100 / small dataset 24, expecting to memorize the answer and style\n",
        "# 1 Qlora finetune with high-sensitive layers 21~31, r = 16: accuracy: % (24 examples with batch size 8) trainable%: 0.0214\n",
        "\n",
        "#1\n",
        "# even with 100 epochs, the model still can't figure out there are true and false, but the format of the explanation is correct!\n",
        "#\n",
        "# ['Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### H',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true\\n         ###',\n",
        "#  'Response:\\n         the correct answer is true\\n         --happy\\n         --happy\\n         --happy\\n   ',\n",
        "#  'Response:\\n         true\\n         ### Expected:\\n         true\\n\\n        ### Instruction:\\n        Pleas',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true\\n         ###',\n",
        "#  'Response:\\n         the federal court is the same as the supreme court\\n         answer format: true/f',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### C',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true\\n         ###',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The above response is correct.\\n\\nAnswer fo',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true\\n         ###',\n",
        "#  'Response:\\n         the correct answer is true\\n         --hieu.le\\n\\nAnswer format: true/false',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         calcium carbide cac2 is the raw material ',\n",
        "#  'Response:\\n         true\\n         ### Expected:\\n         true\\n\\n        ### Instruction:\\n        Pleas',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
        "#  'Response:\\n         true\\n         ### Expected:\\n         true\\n\\nAnswer format: true/false\\n        [/IN',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true.\\n         ##',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
        "#  'Response:\\n         the boy in the plastic bubble based on true story?\\n         true\\n         --mynam',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true\\n         ###',\n",
        "#  'Response:\\n         true\\n         ### Expected:\\n         true\\n\\n        ### Instruction:\\n        Pleas',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### H']\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnDA6txsj7IG",
        "outputId": "8ad81d06-3da8-4a90-fcaa-59dbc00410c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### H',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true\\n         ###',\n",
              " 'Response:\\n         the correct answer is true\\n         --happy\\n         --happy\\n         --happy\\n   ',\n",
              " 'Response:\\n         true\\n         ### Expected:\\n         true\\n\\n        ### Instruction:\\n        Pleas',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true\\n         ###',\n",
              " 'Response:\\n         the federal court is the same as the supreme court\\n         answer format: true/f',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### C',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true\\n         ###',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The above response is correct.\\n\\nAnswer fo',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true\\n         ###',\n",
              " 'Response:\\n         the correct answer is true\\n         --hieu.le\\n\\nAnswer format: true/false',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         calcium carbide cac2 is the raw material ',\n",
              " 'Response:\\n         true\\n         ### Expected:\\n         true\\n\\n        ### Instruction:\\n        Pleas',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
              " 'Response:\\n         true\\n         ### Expected:\\n         true\\n\\nAnswer format: true/false\\n        [/IN',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true.\\n         ##',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
              " 'Response:\\n         the boy in the plastic bubble based on true story?\\n         true\\n         --mynam',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct response is true\\n         ###',\n",
              " 'Response:\\n         true\\n         ### Expected:\\n         true\\n\\n        ### Instruction:\\n        Pleas',\n",
              " 'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### H']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions\n",
        "\n",
        "#--high epochs: 50 / small dataset 24, expecting to memorize the answer and style\n",
        "# 1 Qlora finetune with high-sensitive layers 21~31, r = 16: accuracy: 58.33% (24 examples with batch size 8) trainable%: 0.0214 --true and try to explain why..\n",
        "# 2 #Qlora finetune with low-sensitive layers 2~11, r = 16: accuracy: 37.50% (24 examples with batch size 8) trainable%: 0.0194 -- some is true, some still can't get what we want to\n",
        "#1\n",
        "# ['Response:\\n        \\n        true\\n        \\n        [/INST]\\n\\n        ### Instruction:\\n        Please an',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        [/INST]\\n\\n        ### Instruction:\\n        Please an',\n",
        "#  'Response:\\n        \\n        true\\n\\n        ### Instruction:\\n        Please answer the following queati',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Response:\\n        \\n        false\\n        \\n     ',\n",
        "#  'Response:\\n        \\n        true\\n\\n        ### Response:\\n        \\n        false\\n\\n        ### Response:',\n",
        "#  'Response:\\n         true\\n\\n        ### Instruction:\\n        Please answer the following queation with ',\n",
        "#  'Response:\\n        \\n        true\\n\\n        ### Instruction:\\n        Please answer the following queati',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Explanation:\\n        The federal court is not t',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Explanation:\\n        The response is true becau',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Explanation:\\n        The response is true becau',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Expected Response:\\n        true\\n        \\n      ',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Explanation:\\n        The response is true becau',\n",
        "#  'Response:\\n         true\\n\\n        ### Instruction:\\n        Please answer the following queation with ',\n",
        "#  'Response:\\n         true\\n\\n        ### Instruction:\\n        Please answer the following queation with ',\n",
        "#  'Response:\\n         true\\n\\n        ### Instruction:\\n        Please answer the following queation with ',\n",
        "#  'Response:\\n        \\n        true\\n\\n        ### Instruction:\\n        Please answer the following queati',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Response:\\n        \\n        false\\n        \\n     ',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Explanation:\\n        The response is true becau',\n",
        "#  'Response:\\n        \\n        true\\n        [/INST]\\n\\n        ### Instruction:\\n        Please answer the ',\n",
        "#  'Response:\\n         true\\n\\n        ### Instruction:\\n        Please answer the following queation with ',\n",
        "#  'Response:\\n        \\n        true\\n\\n        ### Instruction:\\n        Please answer the following queati',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Explanation:\\n        The response is true becau',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Response:\\n        \\n        false\\n        \\n     ',\n",
        "#  'Response:\\n        \\n        true\\n\\n        ### Response:\\n        \\n        false\\n\\n        ### Response:']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#2\n",
        "# ['Response:\\n        \\n        true\\n        [/RESP]\\n\\n[INST]<<sys>>Below is an instruction that describes',\n",
        "#  'Response:\\n        \\n        [/INST]\\n        ### Instruction:\\n        Please answer the following quea',\n",
        "#  'Response:\\n        \\n        true\\n        [/RES]\\n\\n[INST]<<sys>>Below is an instruction that describes ',\n",
        "#  'Response:\\n        \\n        true\\n        [/Response]\\n\\n        ### Instruction:\\n        Please answer ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n\\n[INST]<<sys>>Below is an instruction that describes a task. Write',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n\\n[INST]<<sys>>Below is an instruction that describes a task. Write',\n",
        "#  'Response:\\n        \\n        [/INST]\\n\\n[INST]<<sys>>Below is an instruction that describes a task. Writ',\n",
        "#  'Response:\\n        \\n        true\\n        [/RESP]\\n\\n[INST]<<sys>>Below is an instruction that describes',\n",
        "#  'Response:\\n        \\n        true\\n        [/Response]\\n\\n[INST]<<sys>>Below is an instruction that descr',\n",
        "#  'Response:\\n        \\n        [/INST]\\n\\n        ### Instruction:\\n        Please answer the following que',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n\\n[INST]<<sys>>Below is an instruction that describes a task. Write',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n\\n        ### Instruction:\\n        Please answer the following quea',\n",
        "#  'Response:\\n        \\n        [/INST]\\n\\n[INST]<<sys>>Below is an instruction that describes a task. Writ',\n",
        "#  'Response:\\n        1. true\\n        2. false\\n\\n        [/SYS]\\n\\n        ### Instruction:\\n        Please ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n\\n[INST]<<sys>>Below is an instruction that describes a task. Write',\n",
        "#  'Response:\\n        \\n        [/INST]\\n        ### Instruction:\\n        Please answer the following quea',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n\\n[INST]<<sys>>Below is an instruction that describes a task. Write',\n",
        "#  'Response:\\n        \\n        true\\n        [/Response]\\n\\n[INST]<<sys>>Below is an instruction that descr',\n",
        "#  'Response:\\n        \\n        true\\n        [/RESP]\\n\\n[INST]<<sys>>Below is an instruction that describes',\n",
        "#  'Response:\\n         true\\n        [/INST]\\n\\n[INST]<<sys>>Below is an instruction that describes a task.',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n\\n        ### Instruction:\\n        Please answer the following quea',\n",
        "#  'Response:\\n        \\n        true\\n        [/Response]\\n\\n[INST]<<sys>>Below is an instruction that descr',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n\\n        ### Instruction:\\n        Please answer the following quea',\n",
        "#  'Response:\\n        \\n        true\\n        [/Response]\\n\\n[INST]<<sys>>Below is an instruction that descr']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -- epochs 12 (reft paper) / small dataset 24\n",
        "# 3 Qlora finetune with high-sensitive layers 21~31, r = 16: accuracy: 4.17 (24 examples with batch size 8) trainable%: 0.0214--not a single can get the point\n",
        "# 4 #Qlora finetune with low-sensitive layers 2~11, r = 16: accuracy: 8.33% (24 examples with batch size 8) trainable%: 0.0194-- some is true, some still can't get what we want to\n",
        "\n",
        "#3\n",
        "# ['Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        1.\\n        [/INST]\\n        ### Response:\\n        2.\\n        [/INST]\\n        ### Re',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        1. the boy in the plastic bubble based on true story?\\n        true\\n        [/RESP]',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/SYS]\\n        [/END]\\n        [/END]\\n      ']\n",
        "\n",
        "\n",
        "\n",
        "#4\n",
        "# ['Response:\\n        \\n        [/SYS]\\n        [/INST]\\n        ### Instruction:\\n        Please answer the',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/RES]\\n        ### Response:\\n        true\\n        [/RES]\\n        ### Resp',\n",
        "#  'Response:\\n        \\n        [/RESP]\\n        ### Instruction:\\n        Please answer the following quea',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n         true\\n        [/INST]\\n        ### Instruction:\\n        Please answer the following',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/RESP]\\n        ### Response:\\n        true\\n        [/RESP]\\n        ### Re',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n         true\\n        [/INST]\\n        ### Instruction:\\n        Please answer the following',\n",
        "#  'Response:\\n        1.\\n        [/RESP]\\n        ### Response:\\n        2.\\n        [/RESP]\\n        ###',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/INST]\\n        ### Instruction:\\n        Please answer the',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        1. the boy in the plastic bubble based on true story?\\n        true\\n        [/RESP]',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/SYS]\\n        [/END]\\n        [/END]\\n      ']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUr6GDMyV5z-",
        "outputId": "31e879da-a3b2-49b2-9862-42791249ef07"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Response:\\n        \\n        [/SYS]\\n        [/INST]\\n        ### Instruction:\\n        Please answer the',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n        \\n        [/RES]\\n        ### Response:\\n        true\\n        [/RES]\\n        ### Resp',\n",
              " 'Response:\\n        \\n        [/RESP]\\n        ### Instruction:\\n        Please answer the following quea',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n         true\\n        [/INST]\\n        ### Instruction:\\n        Please answer the following',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n        \\n        [/RESP]\\n        ### Response:\\n        true\\n        [/RESP]\\n        ### Re',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n         true\\n        [/INST]\\n        ### Instruction:\\n        Please answer the following',\n",
              " 'Response:\\n        1.\\n        [/RESP]\\n        ### Response:\\n        2.\\n        [/RESP]\\n        ###',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        [/INST]\\n        ### Instruction:\\n        Please answer the',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
              " 'Response:\\n        1. the boy in the plastic bubble based on true story?\\n        true\\n        [/RESP]',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
              " 'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/SYS]\\n        [/END]\\n        [/END]\\n      ']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions\n",
        "\n",
        "# 3 epcohs, 500 examples\n",
        "# test it with validation data\n",
        "#0 full digit model without finetune: accuracy: 8.33% (24 examples with batch size 8) 0% of parameter\n",
        "#1 Qlora finetune with every layer: accuracy: 58.33%, r = 16 (24 examples with batch size 8) trainable%: 0.0622 (positive/negative balancing issue)\n",
        "#2 Qlora finetune with every layer: accuracy: 58.33%, r = 16, providing odd urls (24 examples with batch size 8) trainable%: 0.0622 (fix positive/negative balancing issue) --all positive still\n",
        "\n",
        "#3 Qlora finetune with high-sensitive layers 21~31, r = 16: accuracy: 58.33% all true and try to explain why (24 examples with batch size 8) trainable%: 0.0214\n",
        "#4 Qlora finetune with low-sensitive layers 2~11, r = 8: accuracy: 8.33% (24 examples with batch size 8) trainable%: 0.0097\n",
        "#5 Qlora finetune with low-sensitive layers 2~11, r = 16: accuracy: 58.33% XX  % (24 examples with batch size 8) trainable%: 0.0194 -- true and false repeating, pure coincident\n",
        "\n",
        "\n",
        "# 0\n",
        "# without Lora finetuning\n",
        "# ['Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        1. is house tax and property tax are same?\\n        true\\n        [/RESP]\\n\\n        #',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n         true\\n        [/INST]\\n        ### Response:\\n         false\\n        [/INST]\\n       ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat']\n",
        "\n",
        "\n",
        "# 1\n",
        "# Qlora on every layer: (positive/negative balancing issue)\n",
        "# ['Response:\\n         true\\n         :)\\n\\n       ![/RESP]\\n\\n        ### Instruction:\\n        Please answer',\n",
        "#  'Response:\\n         true\\n         false\\n\\n       ![image](https://user-images.githubusercontent.com/30',\n",
        "#  'Response:\\n         true\\n         true\\n         true\\n         true\\n         true\\n         true\\n      ',\n",
        "#  'Response:\\n         correct answer is true\\n        ![/RESP]\\n\\n        ### Instruction:\\n        Please ',\n",
        "#  'Response:\\n         true\\n         :)\\n\\n        :)\\n\\n        :)\\n\\n        :)\\n\\n        :)\\n\\n        :)\\n\\n   ',\n",
        "#  'Response:\\n         correct answer is:true\\n        \\n       ![INST]',\n",
        "#  'Response:\\n         true\\n         true\\n         true\\n         true\\n         true\\n         true\\n      ',\n",
        "#  'Response:\\n         true\\n         true\\n         true\\n         true\\n         true\\n         true\\n      ',\n",
        "#  'Response:\\n         true\\n         :)\\n\\n       ![/RESP]\\n\\n        ### OR if u answer is false:\\n         ',\n",
        "#  'Response:\\n         true\\n         :)\\n\\n       ![/RESP]\\n\\n        ### OR if the response was:\\n        fa',\n",
        "#  'Response:\\n         correct answer is true\\n        ![/RESP]\\n\\n        ### Instruction:\\n        Please ',\n",
        "#  'Response:\\n         true\\n         true\\n         true\\n         true\\n         true\\n         true\\n      ',\n",
        "#  'Response:\\n         true\\n         true\\n         true\\n         true\\n         true\\n         true\\n      ',\n",
        "#  'Response:\\n         true\\n         true\\n         true\\n         true\\n         true\\n         true\\n      ',\n",
        "#  'Response:\\n         true\\n         :)\\n\\n       ![/RESP]\\n\\n        \\n\\n        \\n\\n        \\n\\n        \\n\\n      ',\n",
        "#  'Response:\\n         true\\n         :)\\n\\n        :)\\n\\n        :)\\n\\n        :)\\n\\n        :)\\n\\n        :)\\n\\n   ',\n",
        "#  'Response:\\n         true\\n         true\\n         true\\n         true\\n         true\\n         true\\n      ',\n",
        "#  'Response:\\n         correct answer is true\\n        \\n       ![INST]',\n",
        "#  'Response:\\n         true\\n         true\\n         true\\n         true\\n         true\\n         true\\n      ',\n",
        "#  'Response:\\n         true\\n         :)\\n\\n        :)\\n\\n        :)\\n\\n        :)\\n\\n        :)\\n\\n        :)\\n\\n   ',\n",
        "#  'Response:\\n         correct answer is true\\n        \\n       ![INST]',\n",
        "#  'Response:\\n         true\\n         :)\\n\\n       ![/RESP]\\n\\n        ### OR if the response was:\\n        fa',\n",
        "#  'Response:\\n         correct answer is: true\\n        \\n       ![INST]',\n",
        "#  'Response:\\n         true\\n         true\\n         true\\n         true\\n         true\\n         true\\n      ']\n",
        "\n",
        "# 2\n",
        "# increase the number of examples, getting more negative examples, and decrease the number of epochs\n",
        "# ['Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XpZWQXq76/giphy.gif)\\n',\n",
        "#  'Response:\\n         true\\n         false\\n         true\\n         false\\n         true\\n         false\\n   ',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XpZZ77776/giphy',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XpZ7777',\n",
        "#  'Response:\\n         true\\n        \\n       ![image](https://user-images.githubusercontent.com/45999272/',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XpZ7X7776/giphy.gif',\n",
        "#  'Response:\\n         true\\n         false\\n         true\\n         false\\n         true\\n         false\\n   ',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XpZWQXq76/giphy.gif)\\n ',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://i.imgur.com/477777.png)\\n        \\n       ![](http',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XpZ777776/giphy.gif',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XpZZ77776/giphy.gif)\\n',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XpZZ77776/giphy.gif)\\n',\n",
        "#  'Response:\\n         true\\n         false\\n\\n       ![image](https://user-images.githubusercontent.com/45',\n",
        "#  'Response:\\n         true\\n        \\n       ![image](https://user-images.githubusercontent.com/49951272/',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://i.imgur.com/000000.png)\\n        \\n       ![](http',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XqXL77776/giphy.',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XpZZ77776/giphy.gif)\\n',\n",
        "#  'Response:\\n         true\\n        \\n       ![image](https://user-images.githubusercontent.com/49951272/',\n",
        "#  'Response:\\n         true\\n         false\\n         correct answer\\n\\n       ![](https://media.giphy.com/m',\n",
        "#  'Response:\\n         true\\n        \\n       ![image](https://user-images.githubusercontent.com/47219772/',\n",
        "#  'Response:\\n         true\\n         true\\n         true\\n         true\\n         true\\n         true\\n      ',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XpZZ77776/giphy.gif)\\n ',\n",
        "#  'Response:\\n         true\\n        \\n        /Response]\\n\\n       ',\n",
        "#  'Response:\\n         true\\n        \\n       ![](https://media.giphy.com/media/3o76XpZWQXq76/giphy.gif)\\n']\n",
        "\n",
        "\n",
        "# 3\n",
        "# try out only applying lora on high-gradient sensitive layers (layer 21~31) with r 16\n",
        "# ['Response:\\n        \\n        true\\n        \\n        ### Explanation:\\n        \\n        Ethanol takes mor',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### H',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true.\\n         ### ',\n",
        "#  'Response:\\n        \\n        the correct answer is true\\n        \\n        ### Explanation:\\n        \\n   ',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### S',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The response is correct.\\n         ### Hin',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true.\\n         ### ',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Explanation:\\n        \\n        The above is a re',\n",
        "#  'Response:\\n         true\\n         best\\n         answer\\n         ever\\n         had\\n         was\\n      ',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### H',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
        "#  'Response:\\n         the correct answer is true\\n         the correct answer is false\\n         the corr',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### R',\n",
        "#  'Response:\\n         the liver is part of the excretory system\\n         true\\n         ### Response:\\n  ',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Explanation:\\n        \\n        The above respons',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### S',\n",
        "#  'Response:\\n         the movie strangers was based on a true story\\n         answer format: true/false\\n',\n",
        "#  'Response:\\n         true\\n         best answer\\n         best answer\\n         best answer\\n         best',\n",
        "#  'Response:\\n         the tv show the resident over for the season?\\n\\nAnswer format: true/false\\n        ',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         Magnesium citrate is a salt of citric aci',\n",
        "#  'Response:\\n         true\\n         best,\\n         thank you\\n         -Mike\\n         ###\\n         ### (',\n",
        "#  'Response:\\n         true\\n         best\\n         answer\\n         ever\\n         had\\n         a\\n        ',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ### Explanation:\\n        \\n        The above respons',\n",
        "#  'Response:\\n         true\\n         ### Explanation:\\n         The correct answer is true\\n         ### H']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 4\n",
        "# try out only applying lora on low-gradient sensitive layers (layer 2~11) with r 8 (reacting dimensions.)\n",
        "# ['Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        1. is house tax and property tax are same?\\n        true\\n        [/RESP]\\n\\n        #',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n         true\\n        [/INST]\\n        ### Response:\\n         false\\n        [/INST]\\n       ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat']\n",
        "\n",
        "\n",
        "\n",
        "# 5\n",
        "# try out only applying lora on low-gradient sensitive layers (layer 2~11) with r 16 (reacting dimensions.)\n",
        "# ['Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
        "#  'Response:\\n        \\n        True\\n        \\n        False\\n        \\n        True\\n        \\n        False\\n',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
        "#  'Response:\\n        \\n        the show bloodline is based on a true story\\n        \\n        ###\\n\\n[INST]<',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        ###\\n\\n        [INST]<<sys>>Below is an instruction t',\n",
        "#  'Response:\\n        \\n        True\\n        \\n        False\\n        \\n        True\\n        \\n        False\\n',\n",
        "#  'Response:\\n        \\n        the movie strangers was based on a true story\\n        \\n        [/MOVIE]\\n\\n',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
        "#  'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false']\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmh-WAHIBCoe",
        "outputId": "24f1dd99-342b-438b-da0b-94442a311a47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
              " 'Response:\\n        \\n        True\\n        \\n        False\\n        \\n        True\\n        \\n        False\\n',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
              " 'Response:\\n        \\n        the show bloodline is based on a true story\\n        \\n        ###\\n\\n[INST]<',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
              " 'Response:\\n        \\n        true\\n        \\n        ###\\n\\n        [INST]<<sys>>Below is an instruction t',\n",
              " 'Response:\\n        \\n        True\\n        \\n        False\\n        \\n        True\\n        \\n        False\\n',\n",
              " 'Response:\\n        \\n        the movie strangers was based on a true story\\n        \\n        [/MOVIE]\\n\\n',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        true\\n        \\n        false\\n',\n",
              " 'Response:\\n        \\n        true\\n        \\n        false\\n        \\n        false\\n        \\n        false']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions\n",
        "#--high epochs: 50 / small dataset 24, expecting to memorize the answer and style\n",
        "# 1 all attention + mlp Qlora finetune with high-sensitive layers 21~31, r = 16: accuracy: 4.17%     (24 examples with batch size 8) trainable%: 0.2035\n",
        "\n",
        "#1\n",
        "# ['Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        1.\\n        [/RESP]\\n        ### Response:\\n        2.\\n        [/RESP]\\n        ###',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        1. the boy in the plastic bubble based on true story?\\n        true\\n        [/RESP]',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/END]\\n        [/END]\\n        [/END]\\n      ',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        ### Instruction:\\n        Please answer the following queat',\n",
        "#  'Response:\\n        \\n        [/SYS]\\n        [/END]\\n        [/SYS]\\n        [/END]\\n        [/END]\\n      ']"
      ],
      "metadata": {
        "id": "uSFiQ-cCfsTM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}